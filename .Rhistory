library(twitteR)
library(plyr)
library(stringr)
library(wordcloud)
library(tm)
api_key <- "ZkbKOcrwHZRB6kWYbnTHmCwjo"
api_secret <- "t4LtacGkPU3vmEMUoV47XrbSo3BU6kBoIFpp3b5RsUX6N0twN1"
access_token <- "767816885765300224-svkvzrZ4Kb5nrSz0xfKnCezrKYjQdKK"
access_token_secret <- "NQirR9pn9KtTWzGwONT7KlwBVvm7ZZEGxgbItQcTHFBhr"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(twitteR)
library(plyr)
library(stringr)
library(wordcloud)
library(tm)
api_key <- "ZkbKOcrwHZRB6kWYbnTHmCwjo"
api_secret <- "t4LtacGkPU3vmEMUoV47XrbSo3BU6kBoIFpp3b5RsUX6N0twN1"
access_token <- "767816885765300224-svkvzrZ4Kb5nrSz0xfKnCezrKYjQdKK"
access_token_secret <- "NQirR9pn9KtTWzGwONT7KlwBVvm7ZZEGxgbItQcTHFBhr"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(twitteR)
library(plyr)
library(stringr)
library(wordcloud)
library(tm)
api_key <- "ZkbKOcrwHZRB6kWYbnTHmCwjo"
api_secret <- "t4LtacGkPU3vmEMUoV47XrbSo3BU6kBoIFpp3b5RsUX6N0twN1"
access_token <- "767816885765300224-svkvzrZ4Kb5nrSz0xfKnCezrKYjQdKK"
access_token_secret <- "NQirR9pn9KtTWzGwONT7KlwBVvm7ZZEGxgbItQcTHFBhr"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
tweets = searchTwitter("#POTUS", n=500)
length(tweets)
Tweets.text = laply(tweets,function(t)t$getText())
pos = scan('/Users/rohantandon/Desktop/CS_590AC/sentiment/positive-words.txt', what='character', comment.char=';')
neg = scan('/Users/rohantandon/Desktop/CS_590AC/sentiment/negative-words.txt', what='character', comment.char=';')
sentiment_analysis = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
value = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences using gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
#to remove emojis
sentence <- iconv(sentence, 'UTF-8', 'ASCII')
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare words to lexicon of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(value)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(value.df)
}
sentiment = sentiment_analysis(Tweets.text, pos, neg)
table(sentiment$value)
mean(sentiment$value)
hist(sentiment$value, xlab  ="Sentiment", ylab = "Frequency")
